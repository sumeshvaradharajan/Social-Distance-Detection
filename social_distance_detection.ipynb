{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t4jCyEGy8OHF"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.spatial import distance as dist\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mfrTHL868Td2"
      },
      "outputs": [],
      "source": [
        "MIN_CONF=0.3\n",
        "NMS_THRESH=0.3\n",
        "MIN_DISTANCE=50\n",
        "\n",
        "\n",
        "def detect_people(frame,net,ln,personIdx=0):\n",
        "  (H,W)=frame.shape[:2] \n",
        "  results=[]\n",
        "\n",
        "  #The cv2.dnn.blobFromImage function returns a blob which is our input image\n",
        "  #after mean subtraction, normalizing, and channel swapping.\n",
        "  blob=cv2.dnn.blobFromImage(frame,1/255.0,(416,416),swapRB=True,crop=False)\n",
        "  net.setInput(blob)\n",
        "  layerOutputs=net.forward(ln)\n",
        "\n",
        "  boxes=[]\n",
        "  centroids=[]\n",
        "  confidences=[]\n",
        "\n",
        "  for output in layerOutputs:\n",
        "    for detection in output:\n",
        "      scores=detection[5:]\n",
        "      classID=np.argmax(scores)\n",
        "      confidence=scores[classID]\n",
        "\n",
        "      if classID == personIdx and confidence > MIN_CONF:\n",
        "        box=detection[0:4] * np.array([W,H,W,H])\n",
        "        (centerX,centerY,width,height)=box.astype(\"int\")\n",
        "\n",
        "#finding top left points\n",
        "        x=int(centerX - (width/2))\n",
        "        y=int(centerY - (height/2))\n",
        "\n",
        "        boxes.append([x,y,int(width),int(height)])\n",
        "        centroids.append((centerX,centerY))\n",
        "        confidences.append(float(confidence))\n",
        "\n",
        "    #apply non-maxima suppression(NMS) to suppress overlapping bounding boxes\n",
        "  idxs=cv2.dnn.NMSBoxes(boxes,confidences,MIN_CONF,NMS_THRESH)\n",
        "  \n",
        "  if len(idxs)>0: # if atleast one detection is found\n",
        "    for i in idxs.flatten():\n",
        "      (x,y)=(boxes[i][0],boxes[i][1])\n",
        "      (w,h)=(boxes[i][2],boxes[i][3])\n",
        "\n",
        "      r=(confidences[i],(x,y,x+w,y+h),centroids[i])\n",
        "      results.append(r)\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxf87HjW8Tow"
      },
      "outputs": [],
      "source": [
        "\n",
        "ap=argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\",\"--input\",type=str,default=\"\",help=\"path to (optional) input video file\")\n",
        "ap.add_argument(\"-o\",\"--output\",type=str,default=\"\",help=\"path to (optional) output video file\")\n",
        "ap.add_argument(\"-d\",\"--display\",type=int,default=1,help=\"whether or not output frame should be displayed\")\n",
        "args=vars(ap.parse_args([\"--input\",\"/content/drive/MyDrive/Datasets/Social_Distance_Detector/crowd video.mp4\", \"--output\",\"/content/drive/MyDrive/Datasets/Social_Distance_Detector/crowd_output_video.avi\",\"--display\",\"1\"]))\n",
        "\n",
        "labelsPath=os.path.sep.join([\"/content/drive/MyDrive/Datasets/Social_Distance_Detector/coco.names\"])\n",
        "LABELS=open(labelsPath).read().strip().split(\"\\n\")\n",
        "\n",
        "#Common Objects in Context (COCO) pre trained weights\n",
        "weightsPath=os.path.sep.join([\"/content/drive/MyDrive/Datasets/Social_Distance_Detector/yolov3 (1).weights\"])\n",
        "configPath=os.path.sep.join([\"/content/drive/MyDrive/Datasets/Social_Distance_Detector/yolov3.cfg\"])\n",
        "\n",
        "net=cv2.dnn.readNetFromDarknet(configPath,weightsPath)\n",
        "\n",
        "ln=net.getLayerNames()\n",
        "ln=[ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "vs=cv2.VideoCapture(args[\"input\"] if args[\"input\"] else 0)\n",
        "writer=None\n",
        "\n",
        "while True:\n",
        "    (grabbed,frame)=vs.read()\n",
        "    \n",
        "    if not grabbed:\n",
        "      break\n",
        "\n",
        "    frame=imutils.resize(frame,width=700)\n",
        "    results=detect_people(frame,net,ln,personIdx=LABELS.index(\"person\"))\n",
        "    violate=set()\n",
        "\n",
        "    if len(results)>=2:\n",
        "      centroids=np.array([r[2] for r in results ])\n",
        "      D=dist.cdist(centroids,centroids,metric=\"euclidean\")\n",
        "\n",
        "      for i in range(0,D.shape[0]):\n",
        "        for j in range(i+1,D.shape[1]):\n",
        "          if D[i,j] < MIN_DISTANCE:\n",
        "            violate.add(i)\n",
        "            violate.add(j)\n",
        "    for(i,(prob,bbox,centroid)) in enumerate(results):\n",
        "      (startX, startY, endX, endY) = bbox\n",
        "      (cX, cY) = centroid\n",
        "      color = (0,255,0)\n",
        "      if i in violate:\n",
        "        color = (0,0,255)\n",
        "\n",
        "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "        cv2.circle(frame, (cX,cY), 5, color, 1)\n",
        "    text = \"Social Distance Violation: {}\".format(len(violate))\n",
        "    cv2.putText(frame, text, (10, frame.shape[0]-25),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0,255,0), 3)\n",
        "    if args[\"display\"] > 0:\n",
        "      cv2_imshow(frame)\n",
        "      key = cv2.waitKey(1) & 0xFF\n",
        "      if key ==ord('q'):\n",
        "        break\n",
        "    if args[\"output\"] !=\"\" and writer is None:\n",
        "      fourcc=cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "      writer=cv2.VideoWriter(args[\"output\"],fourcc,25,(frame.shape[1],frame.shape[0]),True) \n",
        "    if writer is not None:\n",
        "      writer.write(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45AkmcZvCjqj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}